import numpy as np
import pickle
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, 
                           classification_report, confusion_matrix)
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt
import seaborn as sns
import time
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

class SentimentClassifier:
    def __init__(self, features_path="features/tfidf_features.npz", 
                 vectorizer_path="features/tfidf_vectorizer.pkl"):
        """
        æƒ…æ„Ÿåˆ†ç±»å™¨
        Args:
            features_path: ç‰¹å¾æ–‡ä»¶è·¯å¾„
            vectorizer_path: å‘é‡åŒ–å™¨æ–‡ä»¶è·¯å¾„
        """
        self.features_path = features_path
        self.vectorizer_path = vectorizer_path
        self.vectorizer = None
        self.label_encoder = LabelEncoder()
        
        # æ•°æ®
        self.X_train = None
        self.X_val = None  
        self.X_test = None
        self.y_train = None
        self.y_val = None
        self.y_test = None
        
        # æ¨¡å‹
        self.models = {}
        self.results = {}
    
    def load_data(self):
        """åŠ è½½ä¿å­˜çš„ç‰¹å¾å’Œå‘é‡åŒ–å™¨"""
        print("=== åŠ è½½ä¿å­˜çš„æ•°æ® ===")
        
        # 1. åŠ è½½ç‰¹å¾çŸ©é˜µ
        try:
            data = np.load(self.features_path, allow_pickle=True)
            self.X_train = data['X_train']
            self.X_val = data['X_val'] 
            self.X_test = data['X_test']
            self.y_train = data['y_train']
            self.y_val = data['y_val']
            self.y_test = data['y_test']
            data.close()
            
            print(f"âœ… ç‰¹å¾çŸ©é˜µåŠ è½½æˆåŠŸ")
            print(f"   è®­ç»ƒé›†: {self.X_train.shape}")
            print(f"   éªŒè¯é›†: {self.X_val.shape}")  
            print(f"   æµ‹è¯•é›†: {self.X_test.shape}")
            
        except Exception as e:
            print(f"âŒ åŠ è½½ç‰¹å¾çŸ©é˜µå¤±è´¥: {e}")
            return False
        
        # 2. åŠ è½½å‘é‡åŒ–å™¨
        try:
            with open(self.vectorizer_path, 'rb') as f:
                self.vectorizer = pickle.load(f)
            print(f"âœ… å‘é‡åŒ–å™¨åŠ è½½æˆåŠŸ")
            
        except Exception as e:
            print(f"âŒ åŠ è½½å‘é‡åŒ–å™¨å¤±è´¥: {e}")
            return False
        
        # 3. ç¼–ç æ ‡ç­¾ (string -> numeric)
        all_labels = np.concatenate([self.y_train, self.y_val, self.y_test])
        self.label_encoder.fit(all_labels)
        
        self.y_train_encoded = self.label_encoder.transform(self.y_train)
        self.y_val_encoded = self.label_encoder.transform(self.y_val)
        self.y_test_encoded = self.label_encoder.transform(self.y_test)
        
        print(f"âœ… æ ‡ç­¾ç¼–ç å®Œæˆ: {self.label_encoder.classes_}")
        
        return True
    
    def train_models(self):
        """è®­ç»ƒå¤šä¸ªæœºå™¨å­¦ä¹ æ¨¡å‹"""
        print("\n=== è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹ ===")
        
        # åªä½¿ç”¨é€»è¾‘å›å½’æ¨¡å‹
        model_configs = {
            'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000)
        }
        
        print(f"ğŸ“Š æ•°æ®è§„æ¨¡: è®­ç»ƒé›† {self.X_train.shape[0]:,} æ¡ï¼Œç‰¹å¾ç»´åº¦ {self.X_train.shape[1]:,}")
        print(f"ğŸ• é¢„è®¡è®­ç»ƒæ—¶é—´: SVMå¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…...")
        
        for i, (name, model) in enumerate(model_configs.items(), 1):
            print(f"\n{'='*50}")
            print(f"ğŸš€ [{i}/{len(model_configs)}] è®­ç»ƒ {name}")
            print(f"{'='*50}")
            
            # æ˜¾ç¤ºé€»è¾‘å›å½’å‚æ•°
            print("âš™ï¸  é€»è¾‘å›å½’å‚æ•°:")
            print(f"   - æœ€å¤§è¿­ä»£æ¬¡æ•°: {model.max_iter}")
            print(f"   - éšæœºç§å­: {model.random_state}")
            print(f"   - æ­£åˆ™åŒ–å‚æ•° C: {model.C}")
                
            start_time = time.time()
            
            try:
                # è®­ç»ƒæ¨¡å‹
                print(f"â° å¼€å§‹æ—¶é—´: {time.strftime('%H:%M:%S')}")
                print("ğŸ”„ é€»è¾‘å›å½’è®­ç»ƒä¸­...")
                
                model.fit(self.X_train, self.y_train_encoded)
                
                training_time = time.time() - start_time
                print(f"âœ… è®­ç»ƒå®Œæˆ! è€—æ—¶: {training_time:.2f}ç§’")
                
                self.models[name] = model
                
                # åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°
                print("ğŸ“ éªŒè¯é›†è¯„ä¼°ä¸­...")
                val_start = time.time()
                val_pred = model.predict(self.X_val)
                val_time = time.time() - val_start
                val_accuracy = accuracy_score(self.y_val_encoded, val_pred)
                
                print(f"ğŸ¯ éªŒè¯é›†å‡†ç¡®ç‡: {val_accuracy:.4f}")
                print(f"âš¡ é¢„æµ‹è€—æ—¶: {val_time:.2f}ç§’")
                print(f"ğŸ“Š è¾“å…¥ç‰¹å¾æ•°: {model.n_features_in_:,}")
                
            except Exception as e:
                training_time = time.time() - start_time
                print(f"âŒ è®­ç»ƒå¤±è´¥ (è€—æ—¶ {training_time:.2f}ç§’): {e}")
        
        print(f"\nğŸ æ‰€æœ‰æ¨¡å‹è®­ç»ƒå®Œæˆ! æˆåŠŸè®­ç»ƒ {len(self.models)} ä¸ªæ¨¡å‹")
    
    def evaluate_on_test_set(self):
        """åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹ï¼Œè¯¦ç»†å±•ç¤ºæ··æ·†çŸ©é˜µåˆ†æ"""
        print("\n=== æµ‹è¯•é›†è¯„ä¼°ç»“æœ ===")
        
        for name, model in self.models.items():
            print(f"\n{'='*60}")
            print(f"ğŸ“Š {name} è¯¦ç»†è¯„ä¼°ç»“æœ")
            print(f"{'='*60}")
            
            # é¢„æµ‹
            y_pred = model.predict(self.X_test)
            y_pred_proba = None
            if hasattr(model, 'predict_proba'):
                y_pred_proba = model.predict_proba(self.X_test)
            
            # è®¡ç®—æ··æ·†çŸ©é˜µ
            cm = confusion_matrix(self.y_test_encoded, y_pred)
            
            # è·å–æ ‡ç­¾æ˜ å°„ (0=negative, 1=positive)
            labels = self.label_encoder.classes_
            label_to_idx = {label: idx for idx, label in enumerate(labels)}
            
            # æå–æ··æ·†çŸ©é˜µçš„å››ä¸ªå€¼
            # å‡è®¾ 0=negative, 1=positive
            if len(cm) == 2:
                tn, fp, fn, tp = cm.ravel()
                
                print(f"ğŸ” æ··æ·†çŸ©é˜µåˆ†æ:")
                print(f"{'='*40}")
                print(f"                é¢„æµ‹ç»“æœ")
                print(f"å®é™…     Negative  Positive")
                print(f"Negative    {tn:4d}     {fp:4d}    (TN=çœŸé˜´æ€§, FP=å‡é˜³æ€§)")
                print(f"Positive    {fn:4d}     {tp:4d}    (FN=å‡é˜´æ€§, TP=çœŸé˜³æ€§)")
                print(f"{'='*40}")
                
                print(f"\nğŸ“ˆ æ··æ·†çŸ©é˜µè¯¦ç»†è§£é‡Š:")
                print(f"â€¢ TN (çœŸé˜´æ€§): {tn:,} - æ­£ç¡®é¢„æµ‹ä¸º Negative çš„æ ·æœ¬")
                print(f"â€¢ TP (çœŸé˜³æ€§): {tp:,} - æ­£ç¡®é¢„æµ‹ä¸º Positive çš„æ ·æœ¬") 
                print(f"â€¢ FN (å‡é˜´æ€§): {fn:,} - é”™è¯¯é¢„æµ‹ä¸º Negative çš„æ ·æœ¬ (å®é™…æ˜¯ Positive)")
                print(f"â€¢ FP (å‡é˜³æ€§): {fp:,} - é”™è¯¯é¢„æµ‹ä¸º Positive çš„æ ·æœ¬ (å®é™…æ˜¯ Negative)")
                
                # è®¡ç®—å„ç±»åˆ«çš„ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1
                print(f"\nğŸ¯ åˆ†ç±»åˆ«æŒ‡æ ‡:")
                print(f"{'='*50}")
                
                # Negativeç±»åˆ«æŒ‡æ ‡
                neg_precision = tn / (tn + fn) if (tn + fn) > 0 else 0
                neg_recall = tn / (tn + fp) if (tn + fp) > 0 else 0  
                neg_f1 = 2 * (neg_precision * neg_recall) / (neg_precision + neg_recall) if (neg_precision + neg_recall) > 0 else 0
                
                # Positiveç±»åˆ«æŒ‡æ ‡  
                pos_precision = tp / (tp + fp) if (tp + fp) > 0 else 0
                pos_recall = tp / (tp + fn) if (tp + fn) > 0 else 0
                pos_f1 = 2 * (pos_precision * pos_recall) / (pos_precision + pos_recall) if (pos_precision + pos_recall) > 0 else 0
                
                print(f"Negative ç±»åˆ«:")
                print(f"  ç²¾ç¡®ç‡ (Precision): {neg_precision:.4f}")
                print(f"  å¬å›ç‡ (Recall):    {neg_recall:.4f}")
                print(f"  F1åˆ†æ•°:            {neg_f1:.4f}")
                
                print(f"\nPositive ç±»åˆ«:")
                print(f"  ç²¾ç¡®ç‡ (Precision): {pos_precision:.4f}")
                print(f"  å¬å›ç‡ (Recall):    {pos_recall:.4f}")
                print(f"  F1åˆ†æ•°:            {pos_f1:.4f}")
            
            # è®¡ç®—æ•´ä½“æŒ‡æ ‡
            accuracy = accuracy_score(self.y_test_encoded, y_pred)
            precision_macro = precision_score(self.y_test_encoded, y_pred, average='macro')
            recall_macro = recall_score(self.y_test_encoded, y_pred, average='macro')
            f1_macro = f1_score(self.y_test_encoded, y_pred, average='macro')
            
            precision_weighted = precision_score(self.y_test_encoded, y_pred, average='weighted')
            recall_weighted = recall_score(self.y_test_encoded, y_pred, average='weighted')
            f1_weighted = f1_score(self.y_test_encoded, y_pred, average='weighted')
            
            print(f"\nğŸ† æ•´ä½“æ€§èƒ½æŒ‡æ ‡:")
            print(f"{'='*50}")
            print(f"æ€»ä½“å‡†ç¡®ç‡ (Accuracy):        {accuracy:.4f}")
            print(f"å®å¹³å‡ç²¾ç¡®ç‡ (Macro Precision): {precision_macro:.4f}")
            print(f"å®å¹³å‡å¬å›ç‡ (Macro Recall):    {recall_macro:.4f}")
            print(f"å®å¹³å‡F1åˆ†æ•° (Macro F1):       {f1_macro:.4f}")
            print(f"åŠ æƒå¹³å‡ç²¾ç¡®ç‡ (Weighted Precision): {precision_weighted:.4f}")
            print(f"åŠ æƒå¹³å‡å¬å›ç‡ (Weighted Recall):    {recall_weighted:.4f}")
            print(f"åŠ æƒå¹³å‡F1åˆ†æ•° (Weighted F1):       {f1_weighted:.4f}")
            
            # ä¿å­˜ç»“æœ
            self.results[name] = {
                'accuracy': accuracy,
                'precision_macro': precision_macro,
                'recall_macro': recall_macro,
                'f1_macro': f1_macro,
                'precision_weighted': precision_weighted,
                'recall_weighted': recall_weighted,
                'f1_weighted': f1_weighted,
                'confusion_matrix': cm,
                'predictions': y_pred,
                'probabilities': y_pred_proba,
                'tn': tn, 'tp': tp, 'fn': fn, 'fp': fp
            }
            
            # è¯¦ç»†åˆ†ç±»æŠ¥å‘Š
            print(f"\nğŸ“‹ Scikit-learn åˆ†ç±»æŠ¥å‘Š:")
            print(f"{'='*50}")
            target_names = self.label_encoder.classes_
            print(classification_report(self.y_test_encoded, y_pred, 
                                      target_names=target_names))
    
    def plot_confusion_matrix(self):
        """ç»˜åˆ¶é€»è¾‘å›å½’çš„æ··æ·†çŸ©é˜µ"""
        if not self.results:
            print("æ²¡æœ‰è¯„ä¼°ç»“æœå¯ä»¥ç»˜åˆ¶")
            return
            
        name = list(self.models.keys())[0]  # è·å–å”¯ä¸€çš„æ¨¡å‹åç§°
        
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # æ··æ·†çŸ©é˜µçƒ­åŠ›å›¾
        cm = self.results[name]['confusion_matrix']
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                   xticklabels=self.label_encoder.classes_,
                   yticklabels=self.label_encoder.classes_,
                   ax=ax1)
        ax1.set_title(f'{name}\næ··æ·†çŸ©é˜µ')
        ax1.set_xlabel('é¢„æµ‹æ ‡ç­¾')
        ax1.set_ylabel('çœŸå®æ ‡ç­¾')
        
        # æ€§èƒ½æŒ‡æ ‡æŸ±çŠ¶å›¾
        metrics = ['Accuracy', 'Precision (Macro)', 'Recall (Macro)', 'F1 (Macro)']
        values = [
            self.results[name]['accuracy'],
            self.results[name]['precision_macro'],
            self.results[name]['recall_macro'],
            self.results[name]['f1_macro']
        ]
        
        bars = ax2.bar(metrics, values, color=['skyblue', 'lightgreen', 'lightcoral', 'gold'])
        ax2.set_title(f'{name}\næ€§èƒ½æŒ‡æ ‡')
        ax2.set_ylabel('åˆ†æ•°')
        ax2.set_ylim(0, 1)
        
        # åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, value in zip(bars, values):
            height = bar.get_height()
            ax2.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                    f'{value:.4f}', ha='center', va='bottom')
        
        plt.xticks(rotation=45)
        plt.tight_layout()
        plt.savefig('logistic_regression_results.png', dpi=300, bbox_inches='tight')
        print("ğŸ“Š å›¾è¡¨å·²ä¿å­˜ä¸º 'logistic_regression_results.png'")
        plt.show()
    
    def plot_detailed_analysis(self):
        """ç»˜åˆ¶è¯¦ç»†çš„åˆ†æå›¾è¡¨"""
        if not self.results:
            print("æ²¡æœ‰è¯„ä¼°ç»“æœå¯ä»¥ç»˜åˆ¶")
            return
            
        name = list(self.models.keys())[0]
        result = self.results[name]
        
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
        
        # 1. æ··æ·†çŸ©é˜µç»„æˆéƒ¨åˆ†é¥¼å›¾
        tn, tp, fn, fp = result['tn'], result['tp'], result['fn'], result['fp']
        labels = ['TN (çœŸé˜´æ€§)', 'TP (çœŸé˜³æ€§)', 'FN (å‡é˜´æ€§)', 'FP (å‡é˜³æ€§)']
        sizes = [tn, tp, fn, fp]
        colors = ['lightblue', 'lightgreen', 'lightcoral', 'lightyellow']
        
        ax1.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)
        ax1.set_title('æ··æ·†çŸ©é˜µç»„æˆåˆ†å¸ƒ')
        
        # 2. æ­£ç¡®vsé”™è¯¯é¢„æµ‹
        correct = tn + tp
        incorrect = fn + fp
        ax2.bar(['æ­£ç¡®é¢„æµ‹', 'é”™è¯¯é¢„æµ‹'], [correct, incorrect], 
                color=['green', 'red'], alpha=0.7)
        ax2.set_title('é¢„æµ‹å‡†ç¡®æ€§')
        ax2.set_ylabel('æ ·æœ¬æ•°é‡')
        for i, v in enumerate([correct, incorrect]):
            ax2.text(i, v + 50, str(v), ha='center', va='bottom')
        
        # 3. å„ç±»åˆ«æ€§èƒ½å¯¹æ¯”
        neg_precision = tn / (tn + fn) if (tn + fn) > 0 else 0
        neg_recall = tn / (tn + fp) if (tn + fp) > 0 else 0
        pos_precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        pos_recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        
        categories = ['Negative', 'Positive']
        precision_scores = [neg_precision, pos_precision]
        recall_scores = [neg_recall, pos_recall]
        
        x = np.arange(len(categories))
        width = 0.35
        
        ax3.bar(x - width/2, precision_scores, width, label='Precision', alpha=0.8)
        ax3.bar(x + width/2, recall_scores, width, label='Recall', alpha=0.8)
        ax3.set_ylabel('åˆ†æ•°')
        ax3.set_title('å„ç±»åˆ«ç²¾ç¡®ç‡vså¬å›ç‡')
        ax3.set_xticks(x)
        ax3.set_xticklabels(categories)
        ax3.legend()
        ax3.set_ylim(0, 1)
        
        # 4. æ•´ä½“æŒ‡æ ‡é›·è¾¾å›¾é£æ ¼çš„æ¡å½¢å›¾
        metrics = ['Accuracy', 'Precision\n(Macro)', 'Recall\n(Macro)', 'F1\n(Macro)']
        values = [
            result['accuracy'],
            result['precision_macro'], 
            result['recall_macro'],
            result['f1_macro']
        ]
        
        bars = ax4.barh(metrics, values, color=['skyblue', 'lightgreen', 'lightcoral', 'gold'])
        ax4.set_xlabel('åˆ†æ•°')
        ax4.set_title('æ•´ä½“æ€§èƒ½æŒ‡æ ‡')
        ax4.set_xlim(0, 1)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, value in zip(bars, values):
            width = bar.get_width()
            ax4.text(width + 0.01, bar.get_y() + bar.get_height()/2.,
                    f'{value:.4f}', ha='left', va='center')
        
        plt.tight_layout()
        plt.savefig('detailed_analysis.png', dpi=300, bbox_inches='tight')
        print("ğŸ“Š è¯¦ç»†åˆ†æå›¾è¡¨å·²ä¿å­˜ä¸º 'detailed_analysis.png'")
        plt.show()
    
    def predict_new_text(self, text):
        """é¢„æµ‹æ–°æ–‡æœ¬çš„æƒ…æ„Ÿ"""
        if self.vectorizer is None or len(self.models) == 0:
            print("è¯·å…ˆåŠ è½½æ•°æ®å’Œè®­ç»ƒæ¨¡å‹ï¼")
            return None
        
        # é¢„å¤„ç†æ–‡æœ¬
        from preprocess import IMDBPreprocessor
        processor = IMDBPreprocessor("")
        clean_text = processor.remove_html_tags(text)
        clean_text = processor.convert_to_lowercase(clean_text)
        clean_text = processor.remove_special_characters(clean_text)
        clean_text = processor.remove_extra_whitespace(clean_text)
        
        # è½¬æ¢ä¸ºTF-IDFç‰¹å¾
        text_features = self.vectorizer.transform([clean_text])
        
        print(f"\n=== æ–‡æœ¬æƒ…æ„Ÿé¢„æµ‹ ===")
        print(f"åŸæ–‡: {text}")
        print(f"é¢„å¤„ç†å: {clean_text}")
        print(f"\nå„æ¨¡å‹é¢„æµ‹ç»“æœ:")
        
        results = {}
        for name, model in self.models.items():
            pred = model.predict(text_features)[0]
            pred_label = self.label_encoder.inverse_transform([pred])[0]
            
            if hasattr(model, 'predict_proba'):
                proba = model.predict_proba(text_features)[0]
                confidence = max(proba)
                results[name] = {
                    'prediction': pred_label,
                    'confidence': confidence,
                    'probabilities': dict(zip(self.label_encoder.classes_, proba))
                }
                print(f"{name:20s}: {pred_label:8s} (ç½®ä¿¡åº¦: {confidence:.4f})")
            else:
                results[name] = {'prediction': pred_label}
                print(f"{name:20s}: {pred_label}")
        
        return results

def main():
    # åˆ›å»ºåˆ†ç±»å™¨
    classifier = SentimentClassifier()
    
    # åŠ è½½æ•°æ®
    if not classifier.load_data():
        return
    
    # è®­ç»ƒæ¨¡å‹
    classifier.train_models()
    
    # æµ‹è¯•é›†è¯„ä¼°
    classifier.evaluate_on_test_set()
    
    # ç»˜åˆ¶ç»“æœ
    classifier.plot_confusion_matrix()
    classifier.plot_detailed_analysis()
    
    # åˆ›å»ºç»“æœæ‘˜è¦
    print("\n" + "="*80)
    print("ğŸ“Š é€»è¾‘å›å½’æ¨¡å‹æœ€ç»ˆç»“æœæ‘˜è¦")
    print("="*80)
    
    name = list(classifier.results.keys())[0]
    result = classifier.results[name]
    
    print(f"ğŸ† æ¨¡å‹: {name}")
    print(f"ğŸ¯ æµ‹è¯•é›†å‡†ç¡®ç‡: {result['accuracy']:.4f}")
    print(f"ï¿½ æ··æ·†çŸ©é˜µç»Ÿè®¡:")
    print(f"   â€¢ TN (çœŸé˜´æ€§): {result['tn']:,}")
    print(f"   â€¢ TP (çœŸé˜³æ€§): {result['tp']:,}") 
    print(f"   â€¢ FN (å‡é˜´æ€§): {result['fn']:,}")
    print(f"   â€¢ FP (å‡é˜³æ€§): {result['fp']:,}")
    print(f"ğŸ“ˆ æ•´ä½“æ€§èƒ½:")
    print(f"   â€¢ å®å¹³å‡ç²¾ç¡®ç‡: {result['precision_macro']:.4f}")
    print(f"   â€¢ å®å¹³å‡å¬å›ç‡: {result['recall_macro']:.4f}")
    print(f"   â€¢ å®å¹³å‡F1åˆ†æ•°: {result['f1_macro']:.4f}")
    
    # æ¼”ç¤ºé¢„æµ‹æ–°æ–‡æœ¬
    print("\n" + "="*60)
    print("ğŸ”® æ¼”ç¤ºæ–°æ–‡æœ¬é¢„æµ‹")
    print("="*60)
    
    test_texts = [
        "This movie is absolutely amazing! I loved every minute of it.",
        "Terrible film, waste of time. Very disappointed.",
        "The movie was okay, nothing special but not bad either."
    ]
    
    for text in test_texts:
        classifier.predict_new_text(text)
        print("-" * 50)

if __name__ == "__main__":
    main()